<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Intro to Object Detection - Chirag Karia</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">
		<link rel="stylesheet" href="dist/theme/moon.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h3 style="text-align: left">Introduction to Object Detection</h3>
					<img class="r-stretch" src="https://bitmovin.com/wp-content/uploads/2019/08/Object_detection_Blog_Image_Q3_19.jpg">
					<div style="overflow: hidden">
						<h6 style="float: left">OT EngSoc Artificial Intelligence Workshop 01</h6>
						<h6 style="float: right">August 23, 2020</h6>
					</div>
					<div>
						<h6 style="float: left">By: Chirag Karia</h6>
						<h6 style="float: right" >
							<a target="_blank" href="https://bitmovin.com/object-detection/">
								Image Source
							</a>
						</h6>
					</div>
				</section>

				<section>
					<h3 data-id="whoami" class="fade-up">Who Am I?</h3>
					<div style="text-align: left" class="fade-up">
						<ul>
							<li>UOIT SOFE Graduate (April 2019)</li>
							<li>Pursuing an MSc in CS</li>
							<li>Researching 3D perception with computer vision</li>
							<li>Worked at two ML based finance startups</li>
						</ul>
					</div>
				</section>

				<section data-auto-animate>
					<h3 data-id="objdet-motivation">Why Care About Object Detection?</h3>
				</section>
				<section data-auto-animate>
					<div>
<!--						<div style="margin-left: -8em" data-id="objdet-motivation">Why Care About Object Detection?</div>-->
						<h3 data-id="objdet-motivation">Why Care About Object Detection?</h3>
						<div style="text-align: left; font-size: 75%; margin-top: 0.5em">
							<ul>
								<li>Simplest way to facilitate scene understanding</li>
								<li>Good introduction to more complex DL models</li>
								<li>First step in many vision pipelines</li>
								<li class="fragment fade-down" data-id="yolo">Any software company will hire you if you beat SOTA</li>
							</ul>
						</div>
					</div>

					<div class="container r-stretch fragment" style="margin-top: 0.5em">
						<div class="columns is-mobile is-vcentered">
							<div class="column is-half">
								<figure>
									<img class="image" style="margin: auto"
											 src="https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/90590e549b02c6c9d9492f21b549d8edff3cd374_254x191.jpg?">
								</figure>
								<div style="font-size: 75%; margin-top: 0.5em">
									Joseph Redmon
									<ul style="font-size: 50%;">
										<li>PhD student at University of Washington</li>
										<li>Created the YOLO algorithm</li>
										<li>Has worked with research groups at IBM, Google, and Facebook</li>
									</ul>
								</div>
							</div>
							<div class="column is-half fragment" style="font-size: 50%">
								<figure>
									<img class="image" style="height: 18em; width: auto; margin: auto"
											 src="https://img.huffingtonpost.com/asset/5d02306124000051178d34f4.jpeg?ops=scalefit_630_noupscale">
									<figcaption style="margin-top:0.5em">This is his resume.</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section style="text-align: left">
					<h3>Overview</h3>
					<div style="font-size: 75%">
						<ol>
							<li>Summary of Neural Networks</li>
							<ul>
								<li>1.1 - What is a Neuron?</li>
								<li>1.2 - Feed Forward Neural Networks</li>
								<li>1.3 - Convolutional Neural Networks</li>
							</ul>
							<li>Object Detection</li>
							<ul>
								<li>2.1 - Types of Object Detectors</li>
								<li>2.2 - Intersection over Union</li>
								<li>2.3 - Anchor Boxes</li>
								<li>2.4 - Non-Maximum Suppression</li>
								<li>2.5 - Faster R-CNN Pipeline</li>
							</ul>
							<li>Demo</li>
						</ol>
					</div>
				</section>

				<section>
					<h3>Summary of Neural Networks</h3>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<div style="text-align: left">
						<div>ML algorithm:</div>
						<ul>
							<li>Maps a vector of inputs $\vec{x}$ to a single output $\hat y$</li>
							<li>Classification tasks (discrete output)</li>
							<li>Regression tasks (continuous output)</li>
							<li>Inspired by biological neurons</li>
						</ul>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">Biological vs. Artificial Neuron (Perceptron)</h6>
					<div class="container r-stretch" style="margin-top: 0.5em; font-size: 0.5em">
						<div class="columns is-mobile is-vcentered">
							<div class="column is-half">
								<figure>
									<img class="image" style="margin: auto"
											 src="https://upload.wikimedia.org/wikipedia/commons/1/10/Blausen_0657_MultipolarNeuron.png">
								</figure>
							</div>
							<div class="column is-half">
								<figure data-id="perceptron" >
									<img class="image" style="margin: auto"
											 src="https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg">
								</figure>
							</div>
						</div>
						<div class="columns is-mobile is-vcentered">
							<div class="column is-half">
								<a target="_blank" href="https://en.wikipedia.org/wiki/Neuron">Image Source</a>
							</div>
							<div class="column is-half">
								<a target="_blank" href="https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e">
									Image Source
								</a>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">The Perceptron</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered">
							<div class="column is-half" style="font-size: 50%">
								<figure data-id="perceptron">
									<img class="image" style="margin: auto"
											 src="https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="font-size: 55%">
								$$
								\hat y = \varphi \left( \left(\sum_{n=1}^{m} x_n w_n \right) + b \right)
								$$
								<p style="text-align: left">
									if we create row vectors of inputs and weights:
								</p>

								$$
								\begin{aligned}
									\vec x &= [x_1, x_2, ... , x_m, 1] \\
									\vec w &= [w_1, w_2, ... , w_m, b]
								\end{aligned}
								$$

								<p style="text-align: left">
									then:
								</p>

								$$\hat y = \varphi (\vec{x} \cdot \vec{w})$$
							</div>
						</div>
						<p class="fragment fade-down" style="font-size: 65%">
							A neuron is simply a dot product of inputs $\vec x$ and weights $\vec w$ passed through an
							activation function $\varphi$
						</p>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">Activation Functions</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half">
								<figure>
									<img class="image" style="margin: auto"
											 src="https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1547672259/4_jouacz.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://www.datacamp.com/community/tutorials/neural-network-models-r">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="font-size: 80%">
								<ul style="text-align: left">
									<li>Without an activation function, a neuron is simply performing linear regression.</li>
									<li style="margin-top: 0.5em">
										Activation functions are also referred to as non-linearities; they serve to help neurons model
										non-linear domains
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">Activation Functions</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half">
								<figure>
									<img class="image" style="margin: auto"
											 src="https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1547672259/4_jouacz.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://www.datacamp.com/community/tutorials/neural-network-models-r">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="font-size: 80%">
								<ul style="text-align: left">
									<li>Without an activation function, a neuron is simply performing linear regression.</li>
									<li style="margin-top: 0.5em">
										Activation functions are also referred to as non-linearities; they serve to help neurons model
										non-linear domains
									</li>
								</ul>

								<div>
									<div style="text-align: left; margin-top:1em; padding-left:1em" class="r-frame">
										<p><u>Bounds of activation functions</u></p>
										<p>Hyper Tangent Function: $ -1 < x < +1$</p>
										<p>ReLu Function: $ 0 \leq x < + \infty$</p>
										<p>Sigmoid Function: $ 0 < x < +1$</p>
										<p>*Identity Function: $ - \infty < x < + \infty$</p>
									</div>

									<p>*Using an Identity Function is equivalent to not having an activation function at all</p>
								</div>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">How do we train a Neuron?</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half">
								<ul style="text-align: left">
									<li>Take a neuron with $m$ inputs in $\vec x$ and a single output $\hat y$</li>
									<li style="margin-top: 0.5em">Across our dataset we want to minimize the difference between the predicted value $\hat y$ and
										the actual value $y$.
									</li>
									<li style="margin-top: 0.5em">Imagine a function $J(\vec w)$ that takes the current set of weights
										$\vec w$ and calculates the error of our model across a subset of our dataset. The lower this value,
										the better our weights are.
									</li>
									<li style="margin-top: 0.5em">Follow the gradient to the bottom.</li>
								</ul>
							</div>

							<div class="column is-half" style="font-size: 80%">
								<figure data-id="convex">
									<img class="image" style="margin: auto"
											 src="https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">How do we train a Neuron?</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="text-align: left">
								let our loss function ($J$) be Mean Squared Error:

								$$
								J(\vec w) = \frac{1}{N} \sum_{n=1}^{N} (\hat y_n - y_n)^2
								$$

								<div data-id="partials">
									where $N$ is the size of the subset of data. The partial derivatives of $J(\vec w)$ with respect
									to $w_i$ is:

									$$
									\frac{\partial{J(\vec{w})}}{\partial{w_i}} = \frac{2}{N} \sum_{n=1}^{N} x_{(n, i)}(\hat y_n - y_n)
									$$
								</div>

							</div>
							<div class="column is-half" style="font-size: 50%">
								<figure class="r-frame" data-id="perceptron" style="padding: 1em">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e">
											Image Source
										</a>
									</figcaption>
								</figure>

								<figure data-id="convex" style="margin-top: 2em !important; padding: 1em" class="r-frame">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">How do we train a Neuron?</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="text-align: left; font-size: 80%">
								<div data-id="partials">
									where $N$ is the size of the subset of data. The partial derivatives of $J(\vec w)$ with respect
									to $w_i$ is:

									$$
									\frac{\partial{J(\vec{w})}}{\partial{w_i}} = \frac{2}{N} \sum_{n=1}^{N} x_{(n, i)}(\hat y_n - y_n)
									$$
								</div>
								<div data-id="gradient">
									the gradient of $J(\vec w)$ with respect to $\vec w$ is:

									$$
									\nabla_{\vec{w}}J(\vec w) = \begin{bmatrix}
									\frac{\partial{J(\vec{w})}}{\partial{w_1}} \\
									... \\
									\frac{\partial{J(\vec{w})}}{\partial{w_m}}
									\end{bmatrix} = \frac{2}{N} \boldsymbol{X}^T \cdot (\boldsymbol{X} \cdot \vec{w}^T - \boldsymbol{Y})
									$$

									where:
									<div class="columns is-mobile">
										<div class="column is-half has-text-centered">
											$$ \boldsymbol{X} \in \mathbb{R}^{(N \times m)} $$
										</div>

										<div class="column is-half has-text-centered">
											$$ \vec{w}^T \in \mathbb{R}^{m \times 1}$$
										</div>
									</div>

									<div class="columns is-mobile">
										<div class="column is-half has-text-centered">
											$$ \boldsymbol{Y} \in \mathbb{R}^{N \times 1} $$
										</div>

										<div class="column is-half has-text-centered">
											$$ \nabla_{\vec{w}}J(\vec w) \in \mathbb{R}^{m \times 1} $$
										</div>
									</div>
								</div>
							</div>
							<div class="column is-half" style="font-size: 50%">
								<figure class="r-frame" data-id="perceptron" style="padding: 1em">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e">
											Image Source
										</a>
									</figcaption>
								</figure>

								<figure style="margin-top: 2em !important; padding: 1em" class="r-frame">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>What is a Neuron?</h3>
					<h6 style="text-align: left">How do we train a Neuron?</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="text-align: left; font-size: 80%">
								<div data-id="gradient">
									the gradient of $J(\vec w)$ with respect to $\vec w$ is:

									$$
									\nabla_{\vec{w}}J(\vec w) = \begin{bmatrix}
									\frac{\partial{J(\vec{w})}}{\partial{w_1}} \\
									... \\
									\frac{\partial{J(\vec{w})}}{\partial{w_m}}
									\end{bmatrix} = \frac{2}{N} \boldsymbol{X}^T \cdot (\boldsymbol{X} \cdot \vec{w}^T - \boldsymbol{Y})
									$$

									where:
									<div class="columns is-mobile">
										<div class="column is-half has-text-centered">
											$$ \boldsymbol{X} \in \mathbb{R}^{(N \times m)} $$
										</div>

										<div class="column is-half has-text-centered">
											$$ \vec{w}^T \in \mathbb{R}^{m \times 1}$$
										</div>
									</div>

									<div class="columns is-mobile">
										<div class="column is-half has-text-centered">
											$$ \boldsymbol{Y} \in \mathbb{R}^{N \times 1} $$
										</div>

										<div class="column is-half has-text-centered">
											$$ \nabla_{\vec{w}}J(\vec w) \in \mathbb{R}^{m \times 1} $$
										</div>
									</div>
								</div>

								We simply update our weights for the next iteration by:

								$$
								\vec{w}_{next} = \vec{w}^T - \eta\nabla_{\vec{w}}J(\vec w)
								$$

								where $\eta$ is a small constant.

							</div>
							<div class="column is-half" style="font-size: 50%">
								<figure class="r-frame" data-id="perceptron" style="padding: 1em">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e">
											Image Source
										</a>
									</figcaption>
								</figure>

								<figure style="margin-top: 2em !important; padding: 1em" class="r-frame">
									<img class="image" style="margin: auto; width: 80%"
											 src="https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Feed Forward Neural Networks</h3>
				</section>

				<section data-auto-animate>
					<h3>Feed Forward Neural Networks</h3>
					<h6 style="text-align: left">A Single Neuron is not Enough.</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="font-size: 50%">
								<figure class="r-frame" data-id="perceptron" style="padding: 1em">
									<img class="image" style="margin: auto;"
											 src="https://www.researchgate.net/profile/Sandra_Vieira5/publication/312205163/figure/fig1/AS:453658144972800@1485171938968/a-The-building-block-of-deep-neural-networks-artificial-neuron-or-node-Each-input-x.png">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://www.researchgate.net/publication/312205163_Using_deep_learning_to_investigate_the_neuroimaging_correlates_of_psychiatric_and_neurological_disorders_Methods_and_applications">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="text-align: left; font-size: 90%">
								<ul>
									<li>It can only provide a single output value.</li>
									<li style="margin-top: 0.5em">It solely looks at the different weighted combinations of inputs. Does not
										create new <a target="_blank" href="https://www.ritchieng.com/neural-networks-representation/">
											representations
										</a>.
									</li>
									<li style="margin-top: 0.5em">
										Feed forward neural networks, or fully connected networks consist of multiple layers of multiple
										neurons.
									</li>
									<li style="margin-top: 0.5em">
										Each layer acts as the input for the subsequent layer. Each layer can be considered a representation
										of the prior layer.
									</li>

									<li style="margin-top: 0.5em">
										Gradients are calculated after the output of the last layer. They are then propagated back through
										the network (<a target="_blank" href="https://brilliant.org/wiki/backpropagation/">Back-Propagation</a>) to update
										parameters/weights.
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Feed Forward Neural Networks</h3>
					<h6 style="text-align: left">A Single Neuron is not Enough.</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="font-size: 50%">
								<figure class="r-frame" data-id="perceptron" style="padding: 1em">
									<img class="image" style="margin: auto;"
											 src="https://www.researchgate.net/profile/Sandra_Vieira5/publication/312205163/figure/fig1/AS:453658144972800@1485171938968/a-The-building-block-of-deep-neural-networks-artificial-neuron-or-node-Each-input-x.png">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://www.researchgate.net/publication/312205163_Using_deep_learning_to_investigate_the_neuroimaging_correlates_of_psychiatric_and_neurological_disorders_Methods_and_applications">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="text-align: left; font-size: 90%">
								<ul>
									<li>Feed forward networks let us have multiple output values.</li>
									<li style="margin-top: 0.5em">This means we can regress more than 1 output, or
										classify more than 1 class.
									</li>
									<li style="margin-top: 0.5em">Hidden layers also give rise to new internal representations for
										subsequent layers.
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
					<h6 style="text-align: left">Working with High Dimensional Data</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="font-size: 80%">
								<ul>
									<li>
										Let us assume we want to use a neural network with a color image of size 300 pixels x 300 pixels.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										What a computer sees when presented with this image is
											$\vec x \in \mathbb{R}^{H \times W \times 3}$.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										Flattening the image (making it a vector) results in
											$300 \times 300 \times 3 = 270, 000$ inputs.
									</li>
									<li style="margin-top: 0.5em" class="fragment">If we try and train a feed forward neural network, and our first hidden
											layer $l$ consists of $100 \times 100$ neurons we have:

										$$
											100 \times 100 \times (2.7 \times 10^5) = 2.7 \times 10^9
										$$
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										We need 2.7 BILLION parameters for just our first layer!
									</li>
									<li style="margin-top: 0.5em" class="fragment">This is not computationally feasible.</li>
								</ul>
							</div>

							<div class="column is-half" style="font-size: 90%">
								<figure>
									<img class="image" style="margin: auto;"
											 src="https://images.squarespace-cdn.com/content/v1/5c28a79ca9e0286061906e43/1548971303762-CKE6Q5C9P67BBU1U33WZ/ke17ZwdGBToddI8pDm48kDaKWgi9ZE4kr18JcIQXYDwUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcRyPfkO4oZUXpqbrxZOO_6kVHuFgmA3f3VYJqaerg3DGeGc_YQfS_CTc0ZE63H3jv/conv_rgb.png">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://www.esantus.com/blog/2019/1/31/convolutional-neural-networks-a-quick-guide-for-newbies">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
					<h6 style="text-align: left">Working with High Dimensional Data</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="font-size: 80%">
								<figure>
									<img class="image" style="margin: auto;"
											 src="https://cdn-media-1.freecodecamp.org/images/gb08-2i83P5wPzs3SL-vosNb6Iur5kb5ZH43">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://cs231n.github.io/convolutional-networks/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="font-size: 90%">
								<ul>
									<li>
										2D Convolutional networks take a fixed set of neurons and <em>convolve</em> them over the input.
									</li>
									<li style="margin-top: 0.5em">
										In this example we have 2 neurons (referred to as filters here) which take an input of $k \times j
										\times d_{l-1}$ where $k$ and $j$ is our kernel height and width respectively, and $d_{l-1}$ is the
										number of channels (depth) in the previous layer.
									</li>
									<li style="margin-top: 0.5em">
										Thus, both neurons have an input size of $k \times j \times d_{l-1}$. In this example that means
										each neuron has $3 \times 3 \times 3 = 27$ inputs and parameters
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
					<h6 style="text-align: left">Working with High Dimensional Data</h6>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half" style="font-size: 80%">
								<figure>
									<img class="image" style="margin: auto;"
											 src="https://cdn-media-1.freecodecamp.org/images/gb08-2i83P5wPzs3SL-vosNb6Iur5kb5ZH43">
									<figcaption style="margin-top: 0.25em;">
										<a target="_blank" href="https://cs231n.github.io/convolutional-networks/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>

							<div class="column is-half" style="font-size: 90%">
								<ul>
									<li>
										The stride ($s$) of a convolutional neuron defines how many pixels the kernel slides to the right, and
										after there are no more columns, how many pixels does it go down and start again. Here $s = 2$
									</li>
									<li style="margin-top: 0.75em">
										A convolutional layer outputs a <em>feature map</em>. This feature map captures hierarchical
										information about the previous layer. These feature maps form new representations.
									</li>
									<li style="margin-top: 0.75em">
										The height and width of a conv layer's feature map is a function of the neurons' stride and kernel
										size. The depth is equivalent to how many neurons are used.
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
					<h6 style="text-align: left">Working with High Dimensional Data</h6>
					<div class="container r-stretch">
						<figure style="height: 75%; width: auto; font-size: 55%">
							<img class="image" style="margin: auto;"
									 src="https://miro.medium.com/max/3820/1*fLGuAUT5imTIGAeA4zzaWA.png">
							<figcaption>
								<a target="_blank" href="https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac">
									Image Source
								</a>
							</figcaption>
						</figure>

						<ul style="font-size: 55%; padding-top: 2em">
							<li>
								A convolutional layer outputs a <em>feature map</em>. This feature map captures hierarchical
								information about the previous layer. These feature maps form new representations.
							</li>
						</ul>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Convolutional Neural Networks</h3>
					<h6 style="text-align: left">Working with High Dimensional Data</h6>
					<div class="container r-stretch">
						<figure style="font-size: 55%">
							<img class="image" style="margin: auto;"
									 src="https://docs.ecognition.com/v9.5.0/Resources/Images/ECogUsr/UG_CNN_scheme.png">
							<figcaption>
								<a target="_blank" href="https://docs.ecognition.com/v9.5.0/eCognition_documentation/Reference%20Book/23%20Convolutional%20Neural%20Network%20Algorithms/Convolutional%20Neural%20Network%20Algorithms.htm">
									Image Source
								</a>
							</figcaption>
						</figure>

						<ul style="font-size: 55%; padding-top: 2em">
							<li>
								The height and width of a conv layer's feature map is a function of the neurons' stride and kernel
								size. The depth is equivalent to how many neurons are used.
							</li>
						</ul>
					</div>
				</section>

				<section>
					<h3>Object Detection</h3>
				</section>

				<section>
					<h3>Types of Object Detectors</h3>
					<div class="container r-stretch">
						<div class="columns is-mobile">
							<div class="column is-half r-frame">
								Single Shot
							</div>
							<div class="column is-half r-frame">
								Two Shot
							</div>
						</div>
						<div class="columns is-mobile" style="font-size: 65%">
							<div class="column is-half r-frame">
								<ul>
									<li>Takes an input image, and directly predicts bounding boxes and object categories</li>
									<li style="margin-top: 0.5em">Faster than two shot approaches, but less accurate</li>
									<li style="margin-top: 0.5em">Ideal for realtime use cases.</li>
								</ul>
							</div>
							<div class="column is-half r-frame">
								<ul>
									<li>Splits prediction into two steps:</li>
									<ol style="font-size: 90%">
										<li>Generate candidate object proposals (objectness score + bounding box)</li>
										<li style="margin-top: 0.25em">Categorize candidate proposals and refine bounding box</li>
									</ol>
									<li style="margin-top: 0.5em">Slower than single shot approaches, but more accurate</li>
									<li style="margin-top: 0.5em">Ideal for less time sensitive applications</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section>
					<h3>Intersection Over Union</h3>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 65%">
							<div class="column is-half">
								<figure style="font-size: 75%">
									<img class="image" style="margin: auto;"
											 src="https://pyimagesearch.com/wp-content/uploads/2016/09/iou_equation.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
							<div class="column is-half">
								<ul>
									<li>Used to quantify how spatially similar two bounding boxes are.</li>
									<li style="margin-top: 0.5em" class="fragment fade-down">
										Does not take object class into account. Only used to quantify similarity of the size and location of
										boxes.
									</li>
								</ul>
								<div class="fragment fade-up" style="font-size: 75%">
									$$
										IoU(B_1, B_2) = \frac{B_1 \cap B_2}{B_1 \cup B_2}
									$$
									where
									$$
									 0 \leq IoU \leq 1
									$$

									<figure style="font-size: 75%">
										<img class="image" style="margin: auto;"
												 src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQYomZLOfdlO7bjW4xW4m2ybZCsCOqpcay8hQE4O3hi1GuMH85k&s">
										<figcaption style="margin-top: 0.5em">
											<a target="_blank" href="http://ronny.rest/tutorials/module/localization_001/iou/">
												Image Source
											</a>
										</figcaption>
									</figure>
								</div>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Anchor Boxes</h3>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 65%">
							<div class="column is-half">
								<figure style="font-size: 75%">
									<img class="image" style="margin: auto;"
											 src="https://miro.medium.com/max/1204/1*XyPFZnb88Taag29iVQDBng.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://qr.ae/pN2b86">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
							<div class="column is-half" style="font-size: 80%">
								<ul>
									<li>
										It is extremely difficult to train an object detector to output predictions relative to the image
										as a whole.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										Instead we predict relative to <a target="_blank" href="https://d2l.ai/chapter_computer-vision/anchor.html">
										anchor boxes</a>. These are known as priors.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										Anchors are tiled across the image, and each ground truth object is paired with the anchor that it
										has the highest $IoU$ with.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										Additionally, any unused anchor that has an $IoU > 0.7$ with an object (this varies across object
										detectors) is also matched with the corresponding ground truth.
									</li>
									<li style="margin-top: 0.5em" class="fragment">
										This means we can have more than 1 anchor assigned to a single object in the image
									</li>
								</ul>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Anchor Boxes</h3>
					<div class="container r-stretch">
						<div class="columns is-mobile is-vcentered" style="font-size: 65%">
							<div class="column is-half">
								<figure style="font-size: 75%">
									<img class="image" style="margin: auto;"
											 src="https://miro.medium.com/max/1204/1*XyPFZnb88Taag29iVQDBng.png">
								</figure>
							</div>
							<div class="column is-half">
								<figure style="font-size: 75%">
									<img class="image" style="margin: auto; background-color: white"
											 src="https://www.mathworks.com/help/vision/ug/anchorbox_whatis.png">
								</figure>
							</div>
						</div>
						<div class="columns is-mobile is-vcentered" style="font-size: 55%">
							<div class="column is-half">
								<a target="_blank" href="https://qr.ae/pN2b86">
									Image Source
								</a>
							</div>
							<div class="column is-half">
								<a target="_blank" href="https://www.mathworks.com/help/vision/ug/anchor-boxes-for-object-detection.html">
									Image Source
								</a>
							</div>
						</div>
						<div style="text-align: left; font-size: 50%">Our regression targets are:</div>
						<div class="columns is-mobile is-vcentered" style="font-size: 50%">
							<div class="column is-half">
								$$
									x_{\hat y} = \frac{x_{gt} - x_a}{w_a}
								$$

								$$
									w_{\hat y} = \log(\frac{w_{gt}}{w_a})
								$$
							</div>
							<div class="column is-half">
								$$
									y_{\hat y} = \frac{y_{gt} - y_a}{h_a}
								$$

								$$
									h_{\hat y} = \log(\frac{h_{gt}}{h_a})
								$$
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Non-Maximum Suppression</h3>
				</section>

				<section data-auto-animate>
					<h3>Non-Maximum Suppression</h3>
					<div class="container r-stretch" style="font-size: 80%">
						<div class="columns is-mobile is-vcentered" style="font-size: 65%">
							<div class="column is-half" style="text-align: left">
								<ul>
									<li>
										Because we matched multiple anchors to a ground truth box during training, when we evaluate
										predictions we will have multiple predictions for the same object.
									</li>
									<li style="margin-top: 0.5em">
										<a target="_blank" href="https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/">
											Non-Maximum Suppression
										</a> serves to filter out extraneous predictions and give us the final set.
									</li>
									<li style="margin-top: 0.5em">NMS is performed by:
										<ol style="margin-top: 0.25em">
											<li>Sorting all predictions by class and confidence.</li>
											<li style="margin-top: 0.25em">
												Any prediction that is the same class as another prediction, with a lower confidence and an
												$IoU > 0.45$ is dropped
											</li>
										</ol>
									</li>
								</ul>
							</div>
							<div class="column is-half">
								<figure style="font-size: 75%">
									<img class="image" style="margin: auto; background-color: white"
											 src="https://dpzbhybb2pdcj.cloudfront.net/elgendy/v-5/Figures/image038.png">
									<figcaption style="margin-top: 0.5em">
										<a target="_blank" href="https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-7/v-5/207">
											Image Source
										</a>
									</figcaption>
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Faster R-CNN</h3>
				</section>

				<section data-auto-animate>
					<h3>Faster R-CNN</h3>
					<ul>
						<li><a target="_blank" href="https://arxiv.org/abs/1506.01497">Faster R-CNN</a> is a two stage object detection algorithm.</li>
						<li style="margin-top: 0.5em" class="fragment">
							It uses the Region Proposal Network to generate candidate predictions.
						</li>
						<li style="margin-top: 0.5em" class="fragment">
							It then uses the Fast R-CNN to classify the object and refine the bounding box.
						</li>
					</ul>
				</section>

				<section data-auto-animate>
					<h3>Faster R-CNN</h3>
					<div class="container r-stretch">
						<figure style="font-size: 55%">
							<img class="image" style="margin: auto;"
									 src="https://miro.medium.com/max/850/1*Fg7DVdvF449PfX5Fd6oOYA.png">
							<figcaption style="margin-top: 0.5em">
								<a target="_blank" href="https://towardsdatascience.com/faster-rcnn-object-detection-f865e5ed7fc4">
									Image Source
								</a>
							</figcaption>
						</figure>
					</div>
				</section>

				<section data-auto-animate>
					<h3>Demo</h3>
				</section>

				<section data-auto-animate>
					<h3>Demo</h3>
					<div>
						<ol>
							<li>Open the following
								<a target="_blank" href="https://colab.research.google.com/drive/1qt2v8gaa33zVdJHNff_b90bKMdIdPuBx?usp=sharing">
									Colab notebook
								</a>
							</li>
							<li style="margin-top: 1em">
								Hit <code>File > Save a copy in Drive</code> to save the notebook to your own google drive.
							</li>
							<li style="margin-top: 1em">
								Follow along with me!
							</li>
						</ol>
					</div>
				</section>

				<section>
					<h3>Questions?</h3>
				</section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				mouseWheel: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ],

				dependencies: [
					{src: 'plugin/reveald3.js'}
				]
			});
		</script>
	</body>
</html>
