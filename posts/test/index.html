<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>KychDev.net - KychDev.net</title><meta name="gridsome:hash" content="b5744b4665350a707f7a0e8273007cab69347053"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.14"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="152x152" href="/assets/static/favicon.62d22cb.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="120x120" href="/assets/static/favicon.1539b60.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="167x167" href="/assets/static/favicon.dc0cdc5.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="180x180" href="/assets/static/favicon.7b22250.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css"><link rel="preload" href="/assets/css/0.styles.255c2bae.css" as="style"><link rel="preload" href="/assets/js/app.a4e4060b.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--vue-remark-template-vue.6116f497.js" as="script"><link rel="preload" href="/assets/js/vue-remark--content--posts--test-md.6e9b0ad7.js" as="script"><link rel="prefetch" href="/assets/js/page--node-modules--gridsome--app--pages--404-vue.71ff0918.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-vue.a09e1b9c.js"><link rel="prefetch" href="/assets/js/page--src--pages--index-vue.c7d481bf.js"><link rel="prefetch" href="/assets/js/vendors~page--src--pages--index-vue.24c8e310.js"><link rel="prefetch" href="/assets/js/vue-remark--content--tutorials--test-md.584fa0a1.js"><link rel="stylesheet" href="/assets/css/0.styles.255c2bae.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body class="has-navbar-fixed-top" data-vue-tag="%7B%22class%22:%7B%22ssr%22:%22has-navbar-fixed-top%22%7D%7D">
    <div data-server-rendered="true" id="app" class="layout"><nav aria-label="main navigation" id="navbar" role="navigation" class="navbar is-fixed-top"><div class="container"><div class="navbar-brand"><a href="/" class="navbar-item active"><span class="has-text-weight-bold has-text-primary">Kych</span><span class="has-text-weight-bold">:\&gt;</span><span class="has-text-weight-bold has-text-warning">Dev</span></a><a aria-expanded="false" aria-label="menu" data-target="navbarBasicExample" role="button" class="navbar-burger burger"><span aria-hidden="true"></span><span aria-hidden="true"></span><span aria-hidden="true"></span></a></div><div id="navbarBasicExample" class="navbar-menu"><div class="navbar-end"><a href="/files/misc/chirag_karia_resume.pdf" target="_blank" class="navbar-item has-text-warning">
                        Resume
                    </a><a href="/about" class="navbar-item has-text-primary">
                        About Me
                    </a></div></div></div></nav><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous"><div class="container"><div class="section"><div class="content"><div><h1 id="this-is-my-post"><a href="#this-is-my-post" aria-hidden="true"><span class="icon icon-link"></span></a>This is my post</h1><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch


<span class="token keyword">def</span> <span class="token function">get_laplacian</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> scaled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> edge_index<span class="token punctuation">.</span>device
    adj_matrix <span class="token operator">=</span> get_adjacency_matrix<span class="token punctuation">(</span>edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>
    n_nodes <span class="token operator">=</span> adj_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    deg_matrix <span class="token operator">=</span> get_degree_matrix<span class="token punctuation">(</span>adjacency_matrix<span class="token operator">=</span>adj_matrix<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>

    inverse_sqrt_deg <span class="token operator">=</span> deg_matrix<span class="token punctuation">.</span>diag<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span>
    inverse_sqrt_deg<span class="token punctuation">[</span>inverse_sqrt_deg <span class="token operator">==</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'inf'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    inverse_sqrt_deg <span class="token operator">=</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>inverse_sqrt_deg<span class="token punctuation">)</span>

    a_norm <span class="token operator">=</span> inverse_sqrt_deg<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>adj_matrix<span class="token punctuation">)</span><span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>inverse_sqrt_deg<span class="token punctuation">)</span>
    laplacian <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>n<span class="token operator">=</span>n_nodes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span> <span class="token operator">-</span> a_norm

    <span class="token keyword">if</span> scaled <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        laplacian <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>laplacian<span class="token operator">/</span><span class="token number">2.0</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>n<span class="token operator">=</span>n_nodes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    <span class="token keyword">return</span> laplacian


<span class="token keyword">def</span> <span class="token function">get_adjacency_matrix</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> edge_index<span class="token punctuation">.</span>device
    n_nodes <span class="token operator">=</span> edge_index<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

    adj_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> n_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    adj_matrix<span class="token punctuation">[</span>edge_index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

    <span class="token keyword">return</span> adj_matrix


<span class="token keyword">def</span> <span class="token function">get_degree_matrix</span><span class="token punctuation">(</span>adjacency_matrix<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    degree_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>adjacency_matrix<span class="token punctuation">)</span>
    idxer <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> degree_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    degree_matrix<span class="token punctuation">[</span>idxer<span class="token punctuation">,</span> idxer<span class="token punctuation">]</span> <span class="token operator">=</span> adjacency_matrix<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> degree_matrix</code></pre><pre class="language-shell"><code class="language-shell"><span class="token builtin class-name">test</span>
~$: <span class="token builtin class-name">echo</span> this</code></pre><p>Pytorch module for Cheby Convolution is outlined below:</p><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init <span class="token keyword">as</span> init
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Parameter


<span class="token keyword">class</span> <span class="token class-name">ChebConv</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> support_size<span class="token punctuation">,</span> features_in<span class="token punctuation">,</span> features_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChebConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>support_size<span class="token punctuation">,</span> features_in<span class="token punctuation">,</span> features_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>features_out<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>_initialize_params<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_initialize_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weight_initializer<span class="token operator">=</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">,</span> bias_initializer<span class="token operator">=</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">)</span><span class="token punctuation">:</span>
        weight_initializer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        bias_initializer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Tx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> k <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> k <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>scaled_laplacian<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>scaled_laplacian<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Tx_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> Tx_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        Tx_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>Tx_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> Tx_list<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>bias

        <span class="token keyword">return</span> out</code></pre><p>The following is defining a Graph Convolution Network that leverages the chebyconv highlighted above:</p><pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ChebyNet</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChebyNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_1 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span> features_out<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_2 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> features_out<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_3 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> features_out<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index

        scaled_laplacian <span class="token operator">=</span> get_laplacian<span class="token punctuation">(</span>edge_index<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><ul><li>item 1</li><li>item 2</li><li>item 3</li></ul><p>just trying out some inline latex math (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span></span></span></span></span>)</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>I</mi><mi>n</mi></msub><mo>−</mo><mfrac><mn>1</mn><msqrt><mi>D</mi></msqrt></mfrac><msub><mi>W</mi><mrow><mi>a</mi><mi>d</mi><mi>j</mi></mrow></msub><mfrac><mn>1</mn><msqrt><mi>D</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">L = I_{n} - \frac{1}{\sqrt{D}} W_{adj} \frac{1}{\sqrt{D}}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.25144em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.1833349999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.1833349999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><p>where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">I_{n}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> refers to an identity matrix of size <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n \times n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span></span></p><pre class="language-text"><code class="language-text">identity matrix     degree matrix     adjacency matrix
     1 0 0              1 0 0               0 1 0
     0 1 0              0 2 0               1 0 1
     0 0 1              0 0 1               0 1 0</code></pre><pre class="language-text"><code class="language-text">1/root(1)      0       0
   0      1/root(2)    0
   0           0    1/root(1)</code></pre><pre class="language-text"><code class="language-text">   0      1/root(1)    0
1/root(2)     0     1/root(2)
   0      1/root(1)    0</code></pre><pre class="language-text"><code class="language-text">   1      -1/root(1)    0
-1/root(2)     1     -1/root(2)
   0      -1/root(1)    1</code></pre></div></div></div></div></div>
    <script>window.__INITIAL_STATE__={"data":null,"context":{}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script><script src="/assets/js/app.a4e4060b.js" defer></script><script src="/assets/js/page--src--templates--vue-remark-template-vue.6116f497.js" defer></script><script src="/assets/js/vue-remark--content--posts--test-md.6e9b0ad7.js" defer></script>
  </body>
</html>
