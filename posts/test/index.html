<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>KychDev.net - KychDev.net</title><meta name="gridsome:hash" content="3857881e588125148c5e7d6f1ab23814c49d167d"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.14"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="152x152" href="/assets/static/favicon.62d22cb.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="120x120" href="/assets/static/favicon.1539b60.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="167x167" href="/assets/static/favicon.dc0cdc5.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="180x180" href="/assets/static/favicon.7b22250.9bb7ffafafc09ac851d81afb65b8ef59.png"><link data-vue-tag="ssr" rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css"><link rel="preload" href="/assets/css/0.styles.884a7223.css" as="style"><link rel="preload" href="/assets/js/app.415bf80e.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--vue-remark-template-vue.cd4d0f53.js" as="script"><link rel="preload" href="/assets/js/vue-remark--content--posts--test-md.89072133.js" as="script"><link rel="prefetch" href="/assets/js/page--node-modules--gridsome--app--pages--404-vue.71ff0918.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-vue.a09e1b9c.js"><link rel="prefetch" href="/assets/js/page--src--pages--index-vue.c7d481bf.js"><link rel="prefetch" href="/assets/js/vendors~page--src--pages--index-vue.24c8e310.js"><link rel="prefetch" href="/assets/js/vue-remark--content--tutorials--test-md.584fa0a1.js"><link rel="stylesheet" href="/assets/css/0.styles.884a7223.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body class="has-navbar-fixed-top" data-vue-tag="%7B%22class%22:%7B%22ssr%22:%22has-navbar-fixed-top%22%7D%7D">
    <div data-server-rendered="true" id="app" class="layout"><nav aria-label="main navigation" id="navbar" role="navigation" class="navbar is-fixed-top"><div class="container"><div class="navbar-brand"><a href="/" class="navbar-item active"><span class="has-text-weight-bold has-text-primary">Kych</span><span class="has-text-weight-bold">:\&gt;</span><span class="has-text-weight-bold has-text-warning">Dev</span></a><a aria-expanded="false" aria-label="menu" data-target="navbarBasicExample" role="button" class="navbar-burger burger"><span aria-hidden="true"></span><span aria-hidden="true"></span><span aria-hidden="true"></span></a></div><div id="navbarBasicExample" class="navbar-menu"><div class="navbar-end"><a href="/files/misc/chirag_karia_resume.pdf" target="_blank" class="navbar-item has-text-warning">
                        Resume
                    </a><a href="/about" class="navbar-item has-text-primary">
                        About Me
                    </a></div></div></div></nav><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous"><div class="container"><div class="section"><div class="content"><div><h1 id="this-is-my-post"><a href="#this-is-my-post" aria-hidden="true"><span class="icon icon-link"></span></a>This is my post</h1><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch


<span class="token keyword">def</span> <span class="token function">get_laplacian</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> scaled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> edge_index<span class="token punctuation">.</span>device
    adj_matrix <span class="token operator">=</span> get_adjacency_matrix<span class="token punctuation">(</span>edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>
    n_nodes <span class="token operator">=</span> adj_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    deg_matrix <span class="token operator">=</span> get_degree_matrix<span class="token punctuation">(</span>adjacency_matrix<span class="token operator">=</span>adj_matrix<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>

    inverse_sqrt_deg <span class="token operator">=</span> deg_matrix<span class="token punctuation">.</span>diag<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span>
    inverse_sqrt_deg<span class="token punctuation">[</span>inverse_sqrt_deg <span class="token operator">==</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'inf'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    inverse_sqrt_deg <span class="token operator">=</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>inverse_sqrt_deg<span class="token punctuation">)</span>

    a_norm <span class="token operator">=</span> inverse_sqrt_deg<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>adj_matrix<span class="token punctuation">)</span><span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>inverse_sqrt_deg<span class="token punctuation">)</span>
    laplacian <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>n<span class="token operator">=</span>n_nodes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span> <span class="token operator">-</span> a_norm

    <span class="token keyword">if</span> scaled <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        laplacian <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>laplacian<span class="token operator">/</span><span class="token number">2.0</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>n<span class="token operator">=</span>n_nodes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    <span class="token keyword">return</span> laplacian


<span class="token keyword">def</span> <span class="token function">get_adjacency_matrix</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> edge_index<span class="token punctuation">.</span>device
    n_nodes <span class="token operator">=</span> edge_index<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

    adj_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> n_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    adj_matrix<span class="token punctuation">[</span>edge_index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

    <span class="token keyword">return</span> adj_matrix


<span class="token keyword">def</span> <span class="token function">get_degree_matrix</span><span class="token punctuation">(</span>adjacency_matrix<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    degree_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>adjacency_matrix<span class="token punctuation">)</span>
    idxer <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> degree_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    degree_matrix<span class="token punctuation">[</span>idxer<span class="token punctuation">,</span> idxer<span class="token punctuation">]</span> <span class="token operator">=</span> adjacency_matrix<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> degree_matrix</code></pre><p>Pytorch module for Cheby Convolution is outlined below:</p><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init <span class="token keyword">as</span> init
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Parameter


<span class="token keyword">class</span> <span class="token class-name">ChebConv</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> support_size<span class="token punctuation">,</span> features_in<span class="token punctuation">,</span> features_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChebConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>support_size<span class="token punctuation">,</span> features_in<span class="token punctuation">,</span> features_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>features_out<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>_initialize_params<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_initialize_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weight_initializer<span class="token operator">=</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">,</span> bias_initializer<span class="token operator">=</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">)</span><span class="token punctuation">:</span>
        weight_initializer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        bias_initializer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Tx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> k <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> k <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>scaled_laplacian<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                Tx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>scaled_laplacian<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Tx_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> Tx_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        Tx_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>Tx_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> Tx_list<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>bias

        <span class="token keyword">return</span> out</code></pre><p>The following is defining a Graph Convolution Network that leverages the chebyconv highlighted above:</p><pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ChebyNet</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChebyNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_1 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span> features_out<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_2 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> features_out<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>chebconv_3 <span class="token operator">=</span> ChebConv<span class="token punctuation">(</span>support_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> features_in<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> features_out<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index

        scaled_laplacian <span class="token operator">=</span> get_laplacian<span class="token punctuation">(</span>edge_index<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>chebconv_3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scaled_laplacian<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><ul><li>item 1</li><li>item 2</li><li>item 3</li></ul><p>just trying out some inline latex math (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span></span></span></span></span>)</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>ρ</mi><msup><mi>v</mi><mn>2</mn></msup><mi>S</mi><msub><mi>C</mi><mi>L</mi></msub></mrow><annotation encoding="application/x-tex">L = \frac{1}{2} \rho v^2 S C_L</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">ρ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div></div>
    <script>window.__INITIAL_STATE__={"data":null,"context":{}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script><script src="/assets/js/app.415bf80e.js" defer></script><script src="/assets/js/page--src--templates--vue-remark-template-vue.cd4d0f53.js" defer></script><script src="/assets/js/vue-remark--content--posts--test-md.89072133.js" defer></script>
  </body>
</html>
